{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exif import Image\n",
    "from pathlib import Path\n",
    "\n",
    "img = Path(\"/home/pierre/Pictures/Phone-Camera/PXL_20230924_015614422.jpg\")\n",
    "d = Image(open(img, \"rb\"))\n",
    "\n",
    "print(d.get(\"flash\"))\n",
    "\n",
    "def debug(k):\n",
    "    print(k)\n",
    "    return k\n",
    "{\n",
    "    k: str(d.get(k))\n",
    "    for k in dir(d)\n",
    "    if not k.startswith(\"_\") and not callable(d.get(k)) and d.get(k) is not None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add, sub, mul\n",
    "\n",
    "s = \"- * 3 + 1 2 4\"\n",
    "\n",
    "def bob(l):\n",
    "    s = l.pop(0)\n",
    "    if s.isnumeric():\n",
    "        return int(s)\n",
    "    return {\"+\": add, \"-\": sub, \"*\": mul}[s](bob(l), bob(l))\n",
    "\n",
    "bob(s.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add, sub, mul\n",
    "\n",
    "s = \"- * 3 + 1 2 4\"\n",
    "\n",
    "def bob(l):\n",
    "    return int(s) if (s:=l.pop(0)).isnumeric() else {\"+\": add, \"-\": sub, \"*\": mul}[s](bob(l), bob(l))\n",
    "\n",
    "bob(s.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.ExifTags\n",
    "import PIL.Image\n",
    "\n",
    "d = dict(zip(PIL.ExifTags.TAGS.values(), PIL.ExifTags.TAGS.keys()))\n",
    "d[\"UserComment\"]\n",
    "\n",
    "img = PIL.Image.open(\"/home/pierre/repositories/exif-tagger/res/PXL_20231217_005734707.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exif = img.getexif()\n",
    "{\n",
    "    PIL.ExifTags.TAGS[k]: v\n",
    "    for k,v in exif.items()\n",
    "    if k in PIL.ExifTags.TAGS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifd = exif.get_ifd(PIL.ExifTags.IFD.GPSInfo)\n",
    "{\n",
    "    PIL.ExifTags.GPSTAGS[k]: v\n",
    "    for k,v in ifd.items()\n",
    "    if k in PIL.ExifTags.GPSTAGS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"a\": list(range(5)), \"b\": list(range(5,10))}\n",
    ")\n",
    "\n",
    "for i,row in df.iterrows():\n",
    "    print(json.dumps(dict(row)))\n",
    "    # print(dict(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Person:\n",
    "    name: str\n",
    "    surname: str\n",
    "\n",
    "Person(*[\"pierre\",\"louvart\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exif_tagger.database import FaceDatabase,Person\n",
    "from exif_tagger.img_clipper import infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pierre = Person(name=\"Pierre\", surname=\"Louvart\")\n",
    "henri = Person(name=\"Henri\", surname=\"Louvart\")\n",
    "\n",
    "db = FaceDatabase(database_path=\"../db/face-database.sqlite\")\n",
    "\n",
    "face = db.getFaces()[1]\n",
    "infer(db, face)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:50<00:00,  8.43s/it]\n"
     ]
    }
   ],
   "source": [
    "from exif_tagger.embeddings import generate_embeddings\n",
    "embs,names = generate_embeddings(\"/home/pierre/Downloads/VGG-Face2/data/vggface2_test/small_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(\"../res/small_test_embeddings_vg2.npy\", embs.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(names, open(\"../res/names.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "names = np.array(json.load(open(\"../res/names.json\")))\n",
    "\n",
    "embs = np.load(\"../res/embeddings_vg2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_9 = embs[np.array(names) == \"n000009\"] # Asian\n",
    "embs_29 = embs[np.array(names) == \"n000029\"] # Old White\n",
    "embs_40 = embs[np.array(names) == \"n000040\"] # Old White\n",
    "embs_480 = embs[np.array(names) == \"n000480\"] # White Woman\n",
    "embs_2351 = embs[np.array(names) == \"n002351\"] # Black\n",
    "embs_928 = embs[np.array(names) == \"n000928\"] # Black\n",
    "embs_928.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_diag = []\n",
    "scores_full = []\n",
    "scores_tied = []\n",
    "scores_spherical = []\n",
    "X = embs[np.array(names) == \"n000480\"]\n",
    "print(X.shape)\n",
    "# X = embs[np.array(names) == \"n000009\"]\n",
    "for i in range(1, 20):\n",
    "    gm = GaussianMixture(n_components=i, covariance_type=\"diag\")\n",
    "    gm.fit(X)\n",
    "    score = gm.score(X)\n",
    "    scores_diag.append(score)\n",
    "    gm = GaussianMixture(n_components=i, covariance_type=\"spherical\")\n",
    "    gm.fit(X)\n",
    "    score = gm.score(X)\n",
    "    scores_spherical.append(score)\n",
    "    gm = GaussianMixture(n_components=i, covariance_type=\"tied\")\n",
    "    gm.fit(X)\n",
    "    score = gm.score(X)\n",
    "    scores_tied.append(score)\n",
    "    gm = GaussianMixture(n_components=i, covariance_type=\"full\")\n",
    "    gm.fit(X)\n",
    "    score = gm.score(X)\n",
    "    scores_full.append(score)\n",
    "\n",
    "plt.plot(scores_diag)\n",
    "plt.plot(scores_full, color=\"r\")\n",
    "plt.plot(scores_spherical, color=\"g\")\n",
    "plt.plot(scores_tied, color=\"orange\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 0\n",
    "means = []\n",
    "covariances = []\n",
    "weights = []\n",
    "precisions_cholesky_ = []\n",
    "\n",
    "small_embs = PCA(n_components=128).fit_transform(embs)\n",
    "\n",
    "for name in tqdm.tqdm(set(names)):\n",
    "    gm = GaussianMixture(n_components=1)\n",
    "    gm.fit(small_embs[names == name][:])\n",
    "    n_components += len(gm.means_)\n",
    "    means += [gm.means_]\n",
    "    covariances += [gm.covariances_]\n",
    "    weights += [gm.weights_]\n",
    "    precisions_cholesky_ += [gm.precisions_cholesky_]\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_id_map = {name: i for i,name in enumerate(set(names))}\n",
    "classes = [names_to_id_map[name] for name in names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "model = GaussianMixture(n_components=n_components)\n",
    "model.means_ = np.concatenate(means, axis=0)\n",
    "model.covariances_ = np.concatenate(covariances, axis=0)\n",
    "model.precisions_cholesky_ = np.concatenate(precisions_cholesky_, axis=0)\n",
    "model.weights_ = np.ones((n_components,)) / np.sum(n_components)\n",
    "dump(model, \"../res/knn_model.joblib\", compress=9)\n",
    "np.mean(model.predict(small_embs[len(names)//2:]) == classes[len(names)//2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "SVC = GaussianProcessClassifier()\n",
    "# model = GaussianProcessClassifier()\n",
    "# model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "mean_embs = []\n",
    "model.fit(embs[::50], classes[::50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(model.predict(embs[2::50]) == classes[2::50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(model, \"../res/knn_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "beg = \"({[\"\n",
    "end = \")}]\"\n",
    "valid_pairs = list(zip(beg, end))\n",
    "\n",
    "def valid_rec(l: list[str]) -> tuple[str, bool]:\n",
    "    x,s = \"\",True\n",
    "    while len(l) and (x:=l.pop(0)) in beg:\n",
    "        y,ss = valid_rec(l)\n",
    "        x,s = \"\",s and ss and (x, y) in valid_pairs\n",
    "    return (x, s)\n",
    "    \n",
    "def valid(t: str):\n",
    "    return valid_rec(list(t)) == (\"\", True)\n",
    "\n",
    "\n",
    "t1 = \"[]\" # valid\n",
    "t2 = \"[({([{}])})]]\" # invalid\n",
    "t3 = \"[({([{}])})][()[{()[]{}}]]\" # valid\n",
    "t4 = \"[({([{}])})][()[{()[]{}}]])\" # invalid\n",
    "t5 = \"{[({([{}])})][()[{()[]{}}]]\" # invalid\n",
    "\n",
    "valid(t1), valid(t2), valid(t3), valid(t4), valid(t5),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"acdjcb   ask\\n  kkd\\t\\n\"\n",
    "f.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
